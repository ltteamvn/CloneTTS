# -*- coding: utf-8 -*-
"""
Chuyá»ƒn Giá»ng NÃ³i AI â€” Báº£n nÃ¢ng cáº¥p toÃ n diá»‡n
- Äá»c SRT chuáº©n timing, tá»± Ä‘iá»u tá»‘c theo tá»«ng cÃ¢u Ä‘á»ƒ khá»›p cá»­a sá»• thá»i gian
- KhÃ´ng chá»“ng/thiáº¿u giá»¯a cÃ¡c Ä‘oáº¡n
- Tá»± nháº­n GPU (CUDA/MPS) náº¿u cÃ³, fallback CPU
- Giao diá»‡n gá»n Ä‘áº¹p vÃ  chuyÃªn nghiá»‡p hÆ¡n (Gradio + Theme + CSS)
"""

import os
import sys
import json
import math
import time
import asyncio
import threading
from datetime import datetime

import torch
import gradio as gr
import pydub
from pydub.effects import speedup as pydub_speedup
import edge_tts
import srt

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 1) Báº£o Ä‘áº£m import Ä‘Æ°á»£c ChatterboxVC (src/)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))
SRC_PATH = os.path.join(SCRIPT_DIR, "src")
if SRC_PATH not in sys.path:
    sys.path.insert(0, SRC_PATH)

import importlib
import chatterbox.vc
importlib.reload(chatterbox.vc)
from chatterbox.vc import ChatterboxVC

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 2) Thiáº¿t bá»‹: Tá»± nháº­n GPU (CUDA/MPS) náº¿u cÃ³, ngÆ°á»£c láº¡i dÃ¹ng CPU
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def detect_device():
    gpu_name = None
    if torch.cuda.is_available():
        try:
            gpu_name = torch.cuda.get_device_name(0)
        except Exception:
            gpu_name = "CUDA"
        return "cuda", gpu_name
    # Há»— trá»£ MPS (Apple Silicon) náº¿u muá»‘n; náº¿u model khÃ´ng há»— trá»£, sáº½ fallback CPU.
    if hasattr(torch.backends, "mps") and torch.backends.mps.is_available():
        return "mps", "Apple MPS"
    return "cpu", None

DEVICE, GPU_NAME = detect_device()

_vc_model = None
def get_vc_model():
    """Lazy load VC model theo DEVICE Ä‘Ã£ phÃ¡t hiá»‡n."""
    global _vc_model
    if _vc_model is None:
        print(f"[VC] Äang táº£i model trÃªn {DEVICE}{' ('+GPU_NAME+')' if GPU_NAME else ''}â€¦")
        try:
            _vc_model = ChatterboxVC.from_pretrained(DEVICE)
        except Exception as e:
            # Fallback an toÃ n náº¿u MPS khÃ´ng Ä‘Æ°á»£c há»— trá»£
            if DEVICE == "mps":
                print("[VC] MPS khÃ´ng Ä‘Æ°á»£c há»— trá»£. Chuyá»ƒn sang CPU.")
                _vc_model = ChatterboxVC.from_pretrained("cpu")
            else:
                raise e
        print("[VC] Model sáºµn sÃ ng.")
    return _vc_model

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 3) UI log helper (Gradio)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
global_log_messages_vc = []
def yield_vc_updates(log_msg=None, audio_data=None, file_list=None, log_append=True):
    """Cáº­p nháº­t log/Ã¢m thanh/files ra UI (dÃ¹ng vá»›i generator)."""
    global global_log_messages_vc
    # cáº­p nháº­t log
    if log_msg is not None:
        prefix = datetime.now().strftime("[%H:%M:%S]")
        if log_append:
            global_log_messages_vc.append(f"{prefix} {log_msg}")
        else:
            global_log_messages_vc = [f"{prefix} {log_msg}"]
    log_update = gr.update(value="\n".join(global_log_messages_vc))

    # audio output
    audio_update = gr.update(visible=(audio_data is not None),
                             value=audio_data if audio_data is not None else None)
    # file-download output
    files_update = gr.update(visible=(file_list is not None),
                             value=file_list if file_list is not None else [])

    yield log_update, audio_update, files_update

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 4) Táº£i danh sÃ¡ch giá»ng Edge TTS tá»« voices.json
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def load_edge_tts_voices(json_path="voices.json"):
    with open(json_path, "r", encoding="utf-8") as f:
        voices = json.load(f)
    display_list, code_map = [], {}
    for lang, genders in voices.items():
        for gender, items in genders.items():
            for v in items:
                disp = f"{lang} - {gender} - {v['display_name']} ({v['voice_code']})"
                display_list.append(disp)
                code_map[disp] = v["voice_code"]
    display_list.sort()
    return display_list, code_map

EDGE_CHOICES, EDGE_CODE_MAP = load_edge_tts_voices()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 5) Edge TTS helpers (an toÃ n trong mÃ´i trÆ°á»ng cÃ³/khÃ´ng event loop)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def _clamp(v, lo, hi):
    return max(lo, min(hi, v))

def _norm_srt_text(txt: str) -> str:
    # Há»£p nháº¥t dÃ²ng, loáº¡i khoáº£ng tráº¯ng thá»«a
    t = " ".join(str(txt).replace("\n", " ").split())
    return t.strip()

async def _edge_tts_async(text, voice_disp, rate_pct, vol_pct, out_path):
    code = EDGE_CODE_MAP.get(voice_disp)
    if not code:
        raise ValueError("KhÃ´ng tÃ¬m tháº¥y voice trong voices.json.")
    rate_str = f"{int(rate_pct):+d}%"
    vol_str  = f"{int(vol_pct):+d}%"
    comm = edge_tts.Communicate(text, voice=code, rate=rate_str, volume=vol_str)
    await comm.save(out_path)
    return out_path

def run_edge_tts_sync(text, voice_disp, rate_pct, vol_pct, out_path):
    """
    Cháº¡y edge-tts Ä‘á»“ng bá»™, an toÃ n dÃ¹ trong/ngoÃ i event loop (Gradio).
    """
    result = {"path": None, "err": None}

    def _runner():
        try:
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
            p = loop.run_until_complete(_edge_tts_async(text, voice_disp, rate_pct, vol_pct, out_path))
            result["path"] = p
        except Exception as e:
            result["err"] = e
        finally:
            try:
                loop.close()
            except Exception:
                pass

    thread = threading.Thread(target=_runner, daemon=True)
    thread.start()
    thread.join()
    if result["err"] is not None:
        raise result["err"]
    return result["path"]

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 6) SRT â†’ Audio: tá»± Ä‘iá»u tá»‘c Ä‘á»ƒ khá»›p cá»­a sá»• thá»i gian tá»«ng Ä‘oáº¡n
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def _fit_tts_to_window(text, voice_disp, base_rate_pct, vol_pct, target_ms, tmp_dir, idx,
                       tol_ratio=0.08, max_trials=3):
    """
    Sinh TTS cho 1 cÃ¢u vÃ  cá»‘ gáº¯ng cÃ³ Ä‘á»™ dÃ i khá»›p target_ms:
    - Thá»­ Ä‘á»c á»Ÿ tá»‘c Ä‘á»™ base_rate_pct, Ä‘o Ä‘á»™ dÃ i
    - Náº¿u quÃ¡ dÃ i so vá»›i khung, tÄƒng rate tÆ°Æ¡ng á»©ng Ä‘á»ƒ Ä‘áº©y nhanh
    - Náº¿u ngáº¯n, giá»¯ nguyÃªn (sau sáº½ pad im láº·ng). Má»¥c tiÃªu: khÃ´ng cáº¯t chá»¯.
    - Náº¿u váº«n lá»‡ch sau vÃ i láº§n, dÃ¹ng speedup (pydub) nháº¹ Ä‘á»ƒ tinh chá»‰nh (chá»‰ speed-up).
    """
    text = _norm_srt_text(text)
    if target_ms <= 0:
        target_ms = 1  # trÃ¡nh chia 0

    base_factor = 1.0 + (base_rate_pct / 100.0)
    used_rate = base_rate_pct
    wav_path = os.path.join(tmp_dir, f"seg_{idx:04d}.wav")

    # Láº§n 1: tá»‘c Ä‘á»™ gá»‘c
    run_edge_tts_sync(text, voice_disp, used_rate, vol_pct, wav_path)
    seg = pydub.AudioSegment.from_file(wav_path)
    L = len(seg)

    # Náº¿u Ä‘Ã£ khá»›p trong sai sá»‘ cho phÃ©p, tráº£ vá»
    if abs(L - target_ms) / float(target_ms) <= tol_ratio:
        return seg, used_rate

    # Náº¿u dÃ i hÆ¡n nhiá»u, tÄƒng rate Ä‘á»ƒ rÃºt gá»n
    trials = 1
    while L > target_ms and trials < max_trials:
        need_factor = L / float(target_ms)  # cáº§n nhanh hÆ¡n báº¥y nhiÃªu láº§n
        # Tá»‘c Ä‘á»™ má»›i ~ base_factor * need_factor
        new_factor = (1.0 + used_rate / 100.0) * need_factor
        new_rate = int(round((new_factor - 1.0) * 100))
        # Giá»›i háº¡n Ä‘á»ƒ trÃ¡nh quÃ¡ Ä‘Ã 
        new_rate = _clamp(new_rate, -50, 100)
        if new_rate == used_rate:
            new_rate = _clamp(used_rate + 5, -50, 100)
        used_rate = new_rate

        run_edge_tts_sync(text, voice_disp, used_rate, vol_pct, wav_path)
        seg = pydub.AudioSegment.from_file(wav_path)
        L = len(seg)
        trials += 1

    # Náº¿u cÃ²n dÃ i hÆ¡n target má»™t chÃºt, tinh chá»‰nh speedup (pitch cÃ³ thá»ƒ thay Ä‘á»•i nháº¹)
    if L > target_ms:
        factor = L / float(target_ms)
        # pydub_speedup chá»‰ rÃºt ngáº¯n (factor>1). DÃ¹ng 1.0 náº¿u sai sá»‘ ráº¥t nhá».
        if factor > 1.02:
            # pydub_speedup tá»‘c Ä‘á»™ >1 lÃ m ngáº¯n láº¡i
            seg = pydub_speedup(seg, playback_speed=factor, chunk_size=50, crossfade=10)
            L = len(seg)

    # Sau cÃ¹ng: cáº¯t/pad Ä‘á»ƒ Ä‘Ãºng target_ms (cáº¯t chá»‰ cÃ²n 1-2ms sai sá»‘, ná»™i dung Ä‘Ã£ tÄƒng tá»‘c phÃ¹ há»£p)
    if L > target_ms:
        seg = seg[:target_ms]
    elif L < target_ms:
        seg = seg + pydub.AudioSegment.silent(duration=target_ms - L)

    return seg, used_rate

def synthesize_srt_audio_precise(srt_path: str, voice_disp: str, work_dir: str,
                                 base_rate_pct: int, vol_pct: int) -> str:
    """
    Táº¡o 1 file WAV tá»« SRT:
    - TÃ´n trá»ng má»‘c thá»i gian start/end cá»§a tá»«ng cÃ¢u
    - Má»—i cÃ¢u tá»± Ä‘iá»u tá»‘c Ä‘á»ƒ khÃ´ng bá»‹ thÃ² ra khá»i end
    - Äáº£m báº£o toÃ n timeline khÃ´ng chá»“ng/thiáº¿u
    """
    with open(srt_path, "r", encoding="utf-8") as f:
        subs = list(srt.parse(f.read()))
    subs.sort(key=lambda x: (x.start, x.end))

    combined = pydub.AudioSegment.empty()
    current_ms = 0
    tmp_dir = os.path.join(work_dir, "_tmp_srt")
    os.makedirs(tmp_dir, exist_ok=True)

    for i, sub in enumerate(subs, 1):
        start_ms = int(sub.start.total_seconds() * 1000)
        end_ms   = int(sub.end.total_seconds()   * 1000)
        if end_ms <= start_ms:
            # skip Ä‘oáº¡n lá»—i thá»i gian
            continue
        dur_ms   = end_ms - start_ms
        text = _norm_srt_text(sub.content)

        # ThÃªm im láº·ng cho Ä‘áº¿n thá»i Ä‘iá»ƒm báº¯t Ä‘áº§u Ä‘oáº¡n
        if start_ms > current_ms:
            combined += pydub.AudioSegment.silent(duration=start_ms - current_ms)
            current_ms = start_ms
        else:
            # Náº¿u SRT cÃ³ overlap nhÆ°ng ta Ä‘Ã£ Ä‘áº£m báº£o má»—i seg sáº½ fit <= (end-start) nÃªn
            # timeline sáº½ khÃ´ng bá»‹ chá»“ng khi ghÃ©p Ä‘Ãºng theo SRT.
            pass

        seg, used_rate = _fit_tts_to_window(
            text=text,
            voice_disp=voice_disp,
            base_rate_pct=base_rate_pct,
            vol_pct=vol_pct,
            target_ms=dur_ms,
            tmp_dir=tmp_dir,
            idx=i
        )

        combined += seg
        current_ms = end_ms

    out_path = os.path.join(work_dir, "srt_source.wav")
    combined.export(out_path, format="wav")
    # Dá»n dáº¹p táº¡m (cÃ³ thá»ƒ giá»¯ láº¡i Ä‘á»ƒ debug náº¿u muá»‘n)
    try:
        for fn in os.listdir(tmp_dir):
            try:
                os.remove(os.path.join(tmp_dir, fn))
            except Exception:
                pass
        os.rmdir(tmp_dir)
    except Exception:
        pass
    return out_path

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 7) Voice Conversion (chuyá»ƒn giá»ng)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def generate_vc(
    source_audio_path,
    target_voice_path,
    cfg_rate: float,
    sigma_min: float,
    batch_mode: bool,
    batch_parameter: str,
    batch_values: str
):
    model = get_vc_model()
    yield from yield_vc_updates("Khá»Ÿi táº¡o chuyá»ƒn giá»ngâ€¦", log_append=False)

    date_folder = datetime.now().strftime("%Y%m%d")
    work_dir = os.path.join("outputs", "vc", date_folder)
    os.makedirs(work_dir, exist_ok=True)

    def run_once(src, tgt, rate, sigma):
        return model.generate(src, target_voice_path=tgt, inference_cfg_rate=rate, sigma_min=sigma)

    outputs = []
    try:
        if batch_mode:
            try:
                vals = [float(v.strip()) for v in batch_values.split(",") if v.strip()]
            except:
                raise gr.Error("Batch values pháº£i lÃ  sá»‘, phÃ¢n cÃ¡ch bá»Ÿi dáº¥u pháº©y.")
            yield from yield_vc_updates(f"Cháº¡y batch '{batch_parameter}': {vals}")
            for idx, v in enumerate(vals, 1):
                r, s = cfg_rate, sigma_min
                tag = ""
                if batch_parameter == "Inference CFG Rate":
                    r, tag = v, f"cfg_{v}"
                else:
                    s, tag = v, f"sigma_{v}"
                yield from yield_vc_updates(f" â€¢ Má»¥c {idx}/{len(vals)}: {batch_parameter}={v}")
                wav = run_once(source_audio_path, target_voice_path, r, s)
                fn = f"{tag}_{idx}.wav"
                path = os.path.join(work_dir, fn)
                model.save_wav(wav, path)
                outputs.append(path)
                yield from yield_vc_updates(f"ÄÃ£ lÆ°u: {path}")
        else:
            audio = pydub.AudioSegment.from_file(source_audio_path)
            if len(audio) > 40_000:
                yield from yield_vc_updates("Audio dÃ i >40s: tÃ¡ch thÃ nh Ä‘oáº¡n 40sâ€¦")
                chunks = [audio[i:i+40_000] for i in range(0, len(audio), 40_000)]
                temp_paths = []
                for i, chunk in enumerate(chunks):
                    tmp = f"{source_audio_path}_chunk{i}.wav"
                    chunk.export(tmp, format="wav")
                    wav = run_once(tmp, target_voice_path, cfg_rate, sigma_min)
                    outp = os.path.join(work_dir, f"part{i}.wav")
                    model.save_wav(wav, outp)
                    temp_paths.append(outp)
                    try:
                        os.remove(tmp)
                    except Exception:
                        pass
                    yield from yield_vc_updates(f"Xá»­ lÃ½ Ä‘oáº¡n {i+1}/{len(chunks)}")
                # ghÃ©p láº¡i
                combined = pydub.AudioSegment.empty()
                for p in temp_paths:
                    combined += pydub.AudioSegment.from_file(p)
                final = os.path.join(work_dir, "combined.wav")
                combined.export(final, format="wav")
                outputs.append(final)
                yield from yield_vc_updates("Chuyá»ƒn xong.")
            else:
                yield from yield_vc_updates("Äang chuyá»ƒn giá»ngâ€¦")
                wav = run_once(source_audio_path, target_voice_path, cfg_rate, sigma_min)
                outp = os.path.join(work_dir, f"LyTranTTS_{datetime.now().strftime('%H%M%S')}.wav")
                model.save_wav(wav, outp)
                outputs.append(outp)
                yield from yield_vc_updates("HoÃ n thÃ nh.")
    except Exception as e:
        yield from yield_vc_updates(f"Lá»—i: {e}")
        raise

    # Tráº£ vá» audio Ä‘áº§u tiÃªn vÃ  danh sÃ¡ch file káº¿t quáº£
    first = outputs[0] if outputs else None
    yield from yield_vc_updates(log_msg=None, audio_data=first, file_list=outputs)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 8) Wrapper: chá»n nguá»“n (SRT / Edge TTS / File) â†’ VC
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def run_vc_pipeline(
    source_mode,                # "SRT" | "Edge TTS" | "Tá»‡p/Ghi Ã¢m"
    srt_file, srt_voice, srt_rate, srt_vol,
    edge_text, edge_voice, edge_rate, edge_vol,
    src_audio, tgt_audio,
    cfg_rate, sigma_min,
    batch_mode, batch_parameter, batch_values
):
    # Reset log Ä‘áº§u phiÃªn
    yield from yield_vc_updates(f"Báº¯t Ä‘áº§u trÃªn thiáº¿t bá»‹: {DEVICE.upper()}{' - '+GPU_NAME if GPU_NAME else ''}", log_append=False)

    date_folder = datetime.now().strftime("%Y%m%d")
    work_dir = os.path.join("outputs", "vc", date_folder)
    os.makedirs(work_dir, exist_ok=True)

    # 1) Chuáº©n bá»‹ nguá»“n
    if source_mode == "SRT":
        if not srt_file:
            raise gr.Error("HÃ£y táº£i lÃªn file .srt")
        if not srt_voice:
            raise gr.Error("HÃ£y chá»n giá»ng Edge TTS cho SRT.")
        yield from yield_vc_updates("Äang tá»•ng há»£p nguá»“n tá»« SRT (canh má»‘c thá»i gian, tá»± Ä‘iá»u tá»‘c)â€¦")
        source = synthesize_srt_audio_precise(
            srt_path=srt_file.name,
            voice_disp=srt_voice,
            work_dir=work_dir,
            base_rate_pct=int(srt_rate),
            vol_pct=int(srt_vol),
        )
    elif source_mode == "Edge TTS":
        if not edge_text or not edge_voice:
            raise gr.Error("HÃ£y nháº­p vÄƒn báº£n vÃ  chá»n giá»ng cho Edge TTS.")
        yield from yield_vc_updates("Äang táº¡o nguá»“n tá»« Edge TTSâ€¦")
        tmp_path = os.path.join(work_dir, "edge_source.wav")
        run_edge_tts_sync(edge_text, edge_voice, int(edge_rate), int(edge_vol), tmp_path)
        source = tmp_path
    else:  # "Tá»‡p/Ghi Ã¢m"
        if not src_audio:
            raise gr.Error("HÃ£y táº£i lÃªn hoáº·c ghi Ã¢m nguá»“n.")
        source = src_audio

    # 2) Voice Conversion
    if not tgt_audio:
        raise gr.Error("HÃ£y táº£i lÃªn/ghi Ã¢m giá»ng má»¥c tiÃªu (tham chiáº¿u).")

    yield from generate_vc(
        source_audio_path=source,
        target_voice_path=tgt_audio,
        cfg_rate=cfg_rate,
        sigma_min=sigma_min,
        batch_mode=batch_mode,
        batch_parameter=batch_parameter,
        batch_values=batch_values
    )

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 9) Giao diá»‡n Gradio â€” gá»n Ä‘áº¹p vÃ  chuyÃªn nghiá»‡p
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
THEME = gr.themes.Soft(
    primary_hue="indigo",
    neutral_hue="slate",
    radius_size=gr.themes.sizes.radius_sm,
)

CUSTOM_CSS = """
.gradio-container { max-width: 1100px !important; }
.header-title { display:flex; align-items:center; gap:.75rem; }
.badge { padding:.15rem .5rem; border-radius:999px; background:#eef2ff; color:#3730a3; font-weight:600; font-size:.85rem; }
.kv { display:flex; gap:.5rem; flex-wrap:wrap; font-size:.9rem; color:#334155; }
.footer-note { color:#64748b; font-size:.85rem; }
"""

with gr.Blocks(title="Chuyá»ƒn Giá»ng NÃ³i AI â€” Pro", theme=THEME, css=CUSTOM_CSS) as demo:
    with gr.Row():
        with gr.Column():
            gr.Markdown(
                f"""
<div class="header-title">
  <h2>ğŸ™ï¸ Chuyá»ƒn Giá»ng NÃ³i AI â€” Pro</h2>
  <span class="badge">{'GPU: ' + GPU_NAME if GPU_NAME else ('CPU' if DEVICE=='cpu' else DEVICE.upper())}</span>
</div>
<div class="kv">
  <div><strong>Thiáº¿t bá»‹:</strong> {DEVICE.upper()}</div>
  <div><strong>NgÃ y:</strong> {datetime.now().strftime('%d/%m/%Y')}</div>
</div>
""",
                elem_id="header"
            )
        with gr.Column(scale=0.3, min_width=220):
            clear_btn = gr.Button("ğŸ§¹ XÃ³a nháº­t kÃ½", variant="secondary")

    with gr.Row():
        with gr.Column(scale=1, min_width=420):
            gr.Markdown("### 1) Nguá»“n Ã¢m thanh")
            source_mode = gr.Dropdown(
                label="Chá»n nguá»“n",
                choices=["Tá»‡p/Ghi Ã¢m", "SRT", "Edge TTS"],
                value="Tá»‡p/Ghi Ã¢m"
            )

            # --- NhÃ³m SRT ---
            with gr.Group(visible=False) as grp_srt:
                srt_file  = gr.File(file_types=[".srt"], label="Táº£i lÃªn file .srt")
                srt_voice = gr.Dropdown(choices=EDGE_CHOICES, label="Giá»ng Edge TTS (Ä‘á»c SRT)")
                srt_rate  = gr.Slider(-100, 100, value=0, step=1, label="Tá»‘c Ä‘á»™ ná»n SRT (% chuáº©n)")
                srt_vol   = gr.Slider(-100, 100, value=0, step=1, label="Ã‚m lÆ°á»£ng SRT (% chuáº©n)")

            # --- NhÃ³m Edge TTS ---
            with gr.Group(visible=False) as grp_edge:
                edge_text  = gr.Textbox(label="VÄƒn báº£n cho Edge TTS", lines=4, placeholder="Nháº­p ná»™i dungâ€¦")
                edge_voice = gr.Dropdown(choices=EDGE_CHOICES, label="Giá»ng Edge TTS")
                edge_rate  = gr.Slider(-100, 100, value=0, step=1, label="Tá»‘c Ä‘á»™ Edge (% chuáº©n)")
                edge_vol   = gr.Slider(-100, 100, value=0, step=1, label="Ã‚m lÆ°á»£ng Edge (% chuáº©n)")
                gen_edge_btn = gr.Button("ğŸ—£ï¸ Táº¡o Edge TTS (xem/ghi lÃ m nguá»“n)")
                edge_audio   = gr.Audio(label="Nguá»“n Edge TTS", type="filepath", visible=True)

            # --- NhÃ³m File/Ghi Ã¢m ---
            with gr.Group(visible=True) as grp_file:
                src_audio = gr.Audio(sources=["upload","microphone"], type="filepath",
                                     label="Táº£i lÃªn / Ghi Ã¢m nguá»“n")

            gr.Markdown("### 2) Giá»ng má»¥c tiÃªu (tham chiáº¿u)")
            tgt_audio = gr.Audio(sources=["upload","microphone"], type="filepath",
                                 label="Táº£i lÃªn / Ghi Ã¢m giá»ng má»¥c tiÃªu")

            gr.Markdown("### 3) Tham sá»‘ chuyá»ƒn giá»ng")
            cfg_slider  = gr.Slider(0.0, 30.0, value=0.5, step=0.1, label="Inference CFG Rate")
            sigma_input = gr.Number(value=1e-6, label="Sigma Min",
                                    minimum=1e-7, maximum=1e-5, precision=8)

            with gr.Accordion("TÃ¹y chá»n Batch Sweep (nÃ¢ng cao)", open=False):
                batch_chk   = gr.Checkbox(label="KÃ­ch hoáº¡t Batch Sweep", value=False)
                batch_param = gr.Dropdown(choices=["Inference CFG Rate","Sigma Min"],
                                          label="Tham sá»‘ thay Ä‘á»•i")
                batch_vals  = gr.Textbox(placeholder="vÃ­ dá»¥: 0.5,1.0,2.0",
                                         label="GiÃ¡ trá»‹ (phÃ¢n cÃ¡ch dáº¥u pháº©y)")

            run_btn = gr.Button("ğŸš€ Báº¯t Ä‘áº§u chuyá»ƒn giá»ng", variant="primary")

        with gr.Column(scale=1, min_width=420):
            gr.Markdown("### Nháº­t kÃ½")
            log_box = gr.Textbox(interactive=False, lines=16)
            gr.Markdown("### Káº¿t quáº£")
            out_audio = gr.Audio(label="Ã‚m thanh káº¿t quáº£", type="filepath", visible=False)
            out_files = gr.Files(label="Táº£i xuá»‘ng cÃ¡c tá»‡p Ä‘áº§u ra", visible=False)
            gr.Markdown('<div class="footer-note">* Há»‡ thá»‘ng tá»± giá»¯ nguyÃªn ná»™i dung cÃ¢u, chá»‰ thay Ä‘á»•i tá»‘c Ä‘á»™ Ä‘á»ƒ khá»›p khung thá»i gian SRT.</div>')

    # â”€â”€ Toggle hiá»ƒn thá»‹ nhÃ³m theo nguá»“n â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    def _toggle_groups(mode):
        return (
            gr.update(visible=(mode == "SRT")),
            gr.update(visible=(mode == "Edge TTS")),
            gr.update(visible=(mode == "Tá»‡p/Ghi Ã¢m")),
        )

    source_mode.change(
        fn=_toggle_groups,
        inputs=[source_mode],
        outputs=[grp_srt, grp_edge, grp_file]
    )

    # â”€â”€ XÃ³a log â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    def clear_logs():
        global global_log_messages_vc
        global_log_messages_vc = []
        return gr.update(value="")

    clear_btn.click(fn=clear_logs, inputs=None, outputs=[log_box])

    # â”€â”€ Sinh Edge TTS preview/nguá»“n â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    def _gen_edge_preview(text, voice, rate, vol):
        if not text or not voice:
            raise gr.Error("HÃ£y nháº­p vÄƒn báº£n vÃ  chá»n giá»ng Edge TTS.")
        date_folder = datetime.now().strftime("%Y%m%d")
        work_dir = os.path.join("outputs", "vc", date_folder)
        os.makedirs(work_dir, exist_ok=True)
        tmp = os.path.join(work_dir, "edge_preview.wav")
        run_edge_tts_sync(text, voice, int(rate), int(vol), tmp)
        return tmp, tmp

    gen_edge_btn.click(
        fn=_gen_edge_preview,
        inputs=[edge_text, edge_voice, edge_rate, edge_vol],
        outputs=[edge_audio, src_audio]
    )

    # â”€â”€ Cháº¡y pipeline VC â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    run_btn.click(
        fn=run_vc_pipeline,
        inputs=[
            source_mode,
            # SRT
            srt_file, srt_voice, srt_rate, srt_vol,
            # Edge
            edge_text, edge_voice, edge_rate, edge_vol,
            # File
            src_audio, tgt_audio,
            # VC params
            cfg_slider, sigma_input,
            batch_chk, batch_param, batch_vals
        ],
        outputs=[log_box, out_audio, out_files],
        show_progress="minimal"
    )

if __name__ == "__main__":
    # Báº¡n cÃ³ thá»ƒ táº¯t share náº¿u khÃ´ng cáº§n: demo.launch(share=False)
    demo.launch(share=True)
